# Amazon OpenSearch (former Amazon ElasticSearch)

## What is it
Large scale analysis and reporting at petabyte scale

At the beginning it was made for search engine, but now it's not only for search anymore.
Now its primarily for reporting.

Can analyze massive data set a lot faster than i.e. Apache Spark.

* OpenSearch if fork of Elasticsearch and Kibana (visualization tool), of which ElasticSearch was actually build on top of Lucene
* fundamentally is search engine, used for searching using json and fuzzy matching
* not the best tool for storage, specialized in searching the index (so if you e.g. scrap data from web and want to be able to search and still have persisted data storage, it is a good practice to store them first e.g. in dynamodb table and then, based on dynamodb events use lambda to put new documents to elasticsearch index)
* scalable, distributed horizontally
* over years, thanks to addition of new tools, it has become analysis tool
* can be used as data pipeline by using Kinesis (it replaces Beats & LogStash from Elastic Stack)
* managed solution, but not serverless, simillar to EMR (user is not responsible for i.e. server upgrades), instead of installing opensource elasticsearch on many EC2 instances and managed them by user 
* can scale up or ddown without downtime, but it is not automatic
* pay for what you use (instance-hours, storage, data transfer), still idle working instances generate costs
* security assued by network isolation (VPC, default) and encryption both at rest and in-transit

## Renaming to opensearch
Amazon renamed service to Amazon openSearch after licensing dispute in September 2021 - they've forked open source ElasticSearch, it works in very much the same way as the Amazon Elasticsearch, it just has a different name.

## Use cases
* (basic) full-text search
* log analytics
* application monitoring (based on incoming log data)
* security analytics / clickstream analytics (also based on log data)

## Main Concepts
* documents = data are stored as a document (because basically opensearch was for full-text search...). But it is not limited to text - you can store data in json files. Every document has a unique ID and a type
* types = defines schema and mapping shared by documents that represent the same soft of thing/format. But in newer elasticsearch version types are limited and going to be deprecated, because schemas will be derived automatically in future
* indices/indexes = index powers search into all documents within a collection of type, in opensearch we have one type per index. In practice, indexes are list of every word found in documents, thanks to indexes searching documents is very easy (word is connected with documents in which words exist)

## How does it work?
* index is split into shards (allows for horizontal scaling)
* document is hashed and stored in particular shard
* every shard may be on a different node in a cluster
* in opensearch every shard is a self-contained Lucene index of its own (every shard is kindd of separate search engine)
* each index has own primary shard and replicas
* writes are first written to primary shard and then replicated to replica shards
* reads are routed to the primary shard or any of replica shards, opensearch tries to distribute the load of read request between all possible shardsd (both primary and replicas)

## How to query Openseach indexes
OpenSearch allow for query data using REST API. So you can use i.e. elasticsearch python package to send those API requests.

You can also use Kibana, which is graphic interface and allow for query data without knowing API endpoints structure (which is still used under the hood).
Kibana also allows for simple SQL query, which still is translated to API payloads and send asf API requests.

## Visualization results
You can visualize Opensearch results using:
* Kibana - builtin tool in Opensearch
* D3JS - easily embedded in external applications, can visualize any JSON formatted data

## Integration with other AWS Services
* S3 buckets (via Lambda to Kinesis)
* Kinesis Data Streams / Kinesis Firehose
* DynamoDB Streams
* Cloudwatch / cloudtrail (logs subscription can deliver to OpenSearch directly)
* IoT

## Deployment options
* dedicated master node (doesn't hold data, its aim is to manage work on primary and replica shards)
* domains = in AWS opensearch domain is a collection of nodes which can work as a opensearch cluster
* snapshot to S3 - it is possible to make a snapshot of opensearch indices to S3, to prevent from losing data on accidentally delete opensearch cluster

## Security
* resource-based policies (so you can grant operations on certain domain for certain IAM role)
* identity-based policies
* ip-based policies (you can restrict access to selected IP numbers)
* VPC restriction (you can place cluster in VPC with no internet access). You cannot change this option on running cluster, you have to decide it when creating the cluster
* Cognito can be used to grant separate authentication (both using Active Directory, social media identity services or Cognito user pool)

## Anti-patterns
* OLTP = opensearch doesn't have transaction support, use RDS or DynamoDB instead
* ad-hoc data querying = you can do this, but athena is better for this

## Storage types
This is one of the difference vs Elasticsearch - AWS introduce storage types 

By default, your data nodes use "hot" storage - with EBS volumes, faster performance, but the most expensive

As an alternative, you can choose other storage types:
* ultrawarm/warm - uses S3 and caching, best for indices with few writes, slower performance but much lower costs (uses S3 instead of EBS)
* cold - uses S3, it's even cheaper, best use for "periodic research on older data"

Data can be migrated between different storage types

## Index State Management
* automates index management policies - in other words automate operations which can be done on index, for example:
  * delete old indices after a period of time
  * move indices into read only state
  * move indices between storage types
  * reduce replica count over time
  * automate index snapshots

ISM policies run every 30-48 minutes, you can send notifications when done

## Index rollup
You can automatically periodically roll up old data into summarized indices - it allows you save storage costs.

New rolled-up index may have fewer fields.

## Index transforms
like rollup but purpose is to create a different view to analyze data differently

## Cross-cluster replication
You can replace indices across domains, to ensure high availability (prevent from losing data) or to reduce latency (replicate data geographically).

You set up follower index which pulls data from leader index.

You can also copy index on demand by using Remote Reindex functionality.

## Stability
* 3 dedicated master nodes is best practice (avoids split brain when you have two master nodes, and they have different state - who is master then?)
* pay attention on disk space - minimum storage requirements is roughly `source data * (1 + number of replicas) * 1.45`, so with 45% of overhead
* choose correct number of shards (many times needs to be done by trial and error method)
* choose correct instance types (mostly about storage requirements, not about CPU and memory, cause opensearch is storage-heavy). Instances for search have suffix `.search`

## Pricing model
* you pay for your instances per hour (same as for EC2)
* you pay for your EBS volumes (if you use hot storage type, not cold or ultrawarm)
