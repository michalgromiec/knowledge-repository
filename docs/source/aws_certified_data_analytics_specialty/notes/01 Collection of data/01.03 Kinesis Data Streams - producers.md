# Kinesis Producers
Used for gettting data into AWS Kinesis stream

Types of Kinesis Producers:
* SDK - you can use AWS CLI to send records to Kinesis Stream
* KPL - Kinesis Producer Library, have more option than SDK and are able to solve advanced issues
* Kinesis Agent - linux tool which can be used on external linux server and i.e. send logs from this server
* 3rd party applications (Spark, Flume, Kafka Connect, NiFi)

## AWS SDK
* you can send record to stream using `put-record` (one record) or `put-records` (many records) cli command (see examples below)
* PutRecords increase your throughput - it generates less HTTP requests
* can be used on mobile app (Ios, android)
* USE CASE: low throughput, higher latency accepted, simple API, Lambda
* raises ProvisionedThroughputExceeded exemption when go over the limits
  * kinesis simply rejects records exceeding limits, itself not repeat the put operation
  * can be solved by exponential backoff retry (i.e. after 2,4,8,16 seconds) or by increasing number of shards
  * make sure you don't have hot shard (shard for which the most record partition keys are send)

## AWS KPL
KPL = Kinesis Producer Library

* easy to implement C++/Java library (the most often Java is used)
* USE CASE: high throughput, low latency, asynchronous, long running producers, but no in cases when you are focused on very low latency (due to default mini-batch functionality)
* includes automated retry mechanism
* both synchronous and asynchronous API are available - in opposition to AWS SDK when only synchronous is possible
* by default, also submit metrics to cloudwatch, so you can monitor kinesis data stream
* supports mini-batching, enabled by default, used to improve throughput and decrease costs
  * collects records and send to Kinesis Stream in one record (executing on one PutRecords API call)
  * aggregate records to fill 1MB/sec limit, and then send them using one PutRecords API call
  * uses RecordMaxBufferedTime option, default 100ms, which states how long Kinesis has to wait to implement batching on produced records
  * by batching, latency is increased
* compression has to be still implemented by user - uncompression has to be implemented in consumer solution
* **records handled by KPL can be consumed only by KCL** (Kinesis Consumer Library) or special helper library

## Kinesis Agent
java-based agent, built on top of KPL. Monitors server logs and send new records to Kinesis Stream
* available only for linux servers
* features:
  * can write from multiple locations to multiple Kinesis Streams
  * can route based on directory/log file
  * can preprocess data before sending to streams (csv to json, json to csv etc)
  * handles file rotation, retry upon failures...
  * store own metrics in cloudwatch

# Hands-on
## AWS SDK (CLI)
### Stream Management
```commandline
aws kinesis create-stream --stream-name test_mg --shard-count 1 --profile michal --region eu-west-1
aws kinesis list-streams --profile michal --region eu-west-1
aws kinesis describe-stream --stream-name test_mg --region eu-west-1 --profile michal
aws kinesis update-shard-count --stream-name test_mg --target-shard-count 2 --scaling_type UNIFORM_SCALING
aws kinesis delete-stream --stream-name test_mg --profile michal --region eu-west-1
```

### Producer
```commandline
aws kinesis put-record --stream-name test_mg --region eu-west-1 --profile michal --partition-key user1 --data '{"action": "user signup"}' --cli-binary-format raw-in-base64-out
aws kinesis put-record --stream-name test_mg --region eu-west-1 --profile michal --partition-key user1 --data '{"action": "user login"}' --cli-binary-format raw-in-base64-out
```

```commandline
aws kinesis put-records --stream-name test_mg --region eu-west-1 --profile michal --records file://records.json
```
gdzie records.json to:
```json
[
  {
    "PartitionKey": "user1",
    "Data": {
      "action": "user signup"
    }
  },
  {
    "PartitionKey": "user1",
    "Data": {
      "action": "user login"
    }
  },
  {
    "PartitionKey": "user2",
    "Data": {
      "action": "user signup"
    }
  }
]
```

```commandline
aws kinesis put-record --stream-name test_mg --region eu-west-1 --profile michal --partition-key user1 --data-binary fileb://binary-data.bin
```