# Kinesis Data Firehose
Purpose of kinesis firehose is to store data from kinesis streams directly in targets.

Firehose stores data in bigger batches, instead of streaming. It means data availability is **near-real-time**.

* fully managed service, doesn't require any administration
* near real time, minimum 60 seconds latency due to way how it handles data (batching)
* automatic scalling
* supports many data formats
* possible data conversion from json to parquet (using aws glue table schema definitions) or manual conversion using AWS Lambda
* support compression GZIP, ZIP or Snappy (when target is amazon S3) or GZIP (Redshift)
* possible to store all source data on separate S3 bucket (to be able to see source history, ie. in case of transformation failures)
* costs are calculated on size of processed data (so if there is no source data, you pay nothing )

## Available Destinations
* AWS S3
* AWS Redshift (through COPY command issued by Firehose after storing data in S3 bucket)
* AWS ElasticSearch
* datadog
* mongodb
* splunk (aggregate log files, single place where all log files are aggregated)
* (possible other new 3rd party partners)
* custom destinations - via **http endpoint** (API)

## Firehose Buffer Sizing
* firehose accumulate records in a buffer
* buffer is flushed based on time (buffer interval) and size (buffer size) rules
* it means data are stored on target when buffer size or butter time is exceeded
* firehose can automatically increase buffer size to increase throughput

buffer interval range from 60 seconds to 900 seconds (so **minimum is one minute**)
buffer size ranges from 1MB to 128MB for S3 destination or 1MB to 100MB for elasticsearch destination

## Comparison to data streams consumer
* streams data is focused on processing messages, where firehose is focused on data ingestion and delivery
* streams stores data for certain period, while firehose doesn't store data at all - it sends data to target destinations
* firehose has builtin functionality of implementing lambda for processing data, in streams you have to implement it by yourself
* firehose is near-real-time (>1 minute latency) vs streams is real-time (>200ms of latency)
* still, you can use kinesis firehose as a kinesis streams client (in case when more than one client is needed, if there is only firehose enabled you could skip kinesis streams and put records directly to kinesis firehose)