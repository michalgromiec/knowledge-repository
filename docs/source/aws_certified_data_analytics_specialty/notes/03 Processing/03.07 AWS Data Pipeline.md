# AWS Data Pipeline
Task scheduling like oozie which can schedule some operations in AWS (e.g. copy data between S3, execute Spark Application etc)

**Web service** help process and move data between AWS compute and processing services and also on-premises tools.

* destinations: S3, RDS, DynamoDB, Redshift, EMR
* manages task dependencies
* included retries and notification on failures
* has precondition checks
* data sources may be on premises
* includes templates of processes which helps in quick start process (e.g. export dynamodb table to s3, migrate rdbs mysql to s3 etc)
* it looks like this service can be taken down by AWS because it's overlapping usage with AWS Lambda
* create and close EC2 or emr cluster automatically, underneath the pipeline
* you can run data pipeline also on-premise, by installing Task Runner. In such case, your on-premise server will poll task from data pipeline service and run shell script

Contains 4 object types:
* datanodes
* activities
* preconditions (e.g. to check if source is available or is s3 key present)
* schedules

![img_7.png](img_7.png)