# S3DictCP
* used for copying large amounts of data from S3 to HDFS or in the opposite way
* uses MapReduce to copy data in a distribute manner
* copies data in distrbuted manner by using all nodes in your cluster

# Other Tools
* ganglia (monitoring cluster status)
* mahout (machine learning on clusters, competitor of spark mllib)
* accumulo (another nosql database)
* sqoop (relational database connector, used for importing data from external databases in distributed manner)
* hcatalog (table and storage management for hive metastore)
* kinesis connector ()
* tachyon (accelerator for Spark, addon)
* derby (open-source relational DB in java)
* ranger (data security manager for Hadoop)
* other software (you can install any external library, as node is EC2 instance...)

# EMR Security
* IAM policies - permissions for EMR for Users
* Kerberos - user authentication
* SSH - secure connection to command line of nodes, can be used for tunneling to web interfaces
* IAM roles
* "block public access" - you can prevent public access to data stored on EMR cluster, can be set before creating the cluster, block access to cluster, not for data

# EMR instance types
* for master node, AWS recommend m5.xlarge if cluster contains less than 50 nodes, above this limit WS recommend larger master node
* for core&task nodes, 
  * AWS recommend m5.xlarge
  * if node have external dependencies (e.g. web crawlers), AWS recommend less expensive t2.medium
  * if you need improved performance, use m4.xlarge
  * obviously, for more computational intensive application, choose instances with higher number of VCPu
* spot instances are always good choice for task nodes
* AWS do not recommend spot instances for core&master node (risk of data loss)

